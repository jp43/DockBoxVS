#!/usr/bin/env python
import os
import sys
import shutil
import math
from glob import glob
import argparse

import numpy as np
import pandas as pd
import nwalign as nw

from mdkit.utility import mol2
from mdkit.utility import utils
from dockbox import pyqcprot

residues_3_to_1 = {'ALA': 'A',
'ARG': 'R',
'ASN': 'N',
'ASP': 'D',
'CYS': 'C',
'GLU': 'E', 
'GLY': 'G',
'HIS': 'H',
'ILE': 'I',
'LEU': 'L',
'LYS': 'K',
'MET': 'M',
'PHE': 'F',
'PRO': 'P',
'GLN': 'Q',
'SER': 'S',
'SEC': 'U',
'THR': 'T',
'TRP': 'W',
'TYR': 'Y',
'VAL': 'V'}

equivalent_residues = {'CYM': 'CYS',
'LYN': 'LYS',
'ASH': 'ASP',
'CYX': 'CYS',
'GLH': 'GLU',
'HID': 'HIS',
'HIE': 'HIS',
'HIP': 'HIS'}

# prefix to identify ligand, target and isomer directories
ligdir_prefix = 'lig'
tardir_prefix = 'target'
isodir_prefix = 'isomer'

# command-line arguments and options
parser = argparse.ArgumentParser(description="Extract best docking poses after rundbx finished.")

parser.add_argument('-all-targets',
    dest='combine_targets',
    action='store_true',
    default=False,
    help='Select best poses over all the targets. If not specified, extract best pose separately for each target. A "%s/%s/%s" architecture \
of the folders is assumed'%(ligdir_prefix,tardir_prefix,isodir_prefix))

parser.add_argument('-all-isomers',
    dest='combine_isomers',
    action='store_true',
    default=False,
    help='Select best poses over all the isomers. If not specified, extract best pose separately for every isomer. A "%s/%s/%s" architecture \
of the folders is assumed'%(ligdir_prefix,tardir_prefix,isodir_prefix))

parser.add_argument('-csvl',
    type=str,
    dest='csvfile_l',
    metavar='FILE',
    help='Filename containing info about compounds. Used to add names of compounds. Default: none')

parser.add_argument('-csvr',
    dest='csvfile_r',
    default=None,
    metavar='FILENAME',
    help='Filename containing info about targets. If none, will look for a receptor file in the "poses" folders.  Default: none')

parser.add_argument('-cutoff',
    dest='cutoff',
    type=float,
    metavar='RMSD_VALUE',
    default=2.0,
    help='RMSD cutoff used for consensus docking or score-based consensus docking. Default: 2.0 A')

parser.add_argument('-d',
    dest='docking_programs',
    nargs='+',
    metavar=('PRGM1', 'PRGM2'),
    help='Docking programs (instances) to be considered when extracting best poses')

parser.add_argument('-dirs',
    dest='dirs',
    nargs='+',
    default=['.'],
    metavar=('DIR1', 'DIR2'),
    help='Directories considered for analysis. Should contain a folder called "poses". Default: curr. dir')

parser.add_argument('-r',
    dest='resultsdir',
    default='results',
    metavar='DIRECTORY NAME',
    help='Name of results directory. Default: results')

group = parser.add_mutually_exclusive_group(required=False)

group.add_argument('-s',
    nargs='+',
    dest='sf',
    metavar='FUNC',
    help='Scoring functions used to extract the best pose (combination of scores)')

group.add_argument('-cd',
    dest='cd',
    nargs='+',
    metavar='PRGM',
    help='Docking programs used for standard consensus docking')

group.add_argument('-sbcd',
    dest='sbcd',
    nargs='+',
    metavar='FUNC',
    help='Scoring functions used for score-based consensus docking')

# update parsers with arguments
args = parser.parse_args()

def compute_rmsd(file1, file2, rotmat=np.eye(3), trans1=np.zeros(3), trans2=np.zeros(3)):
    """Compute RMSD between 2 poses"""

    # load coordinates of first pose (non-hydrogen atoms)
    coords1 = mol2.get_coordinates(file1, keep_h=False)
    coords1 = np.array(coords1)
    natoms = coords1.shape[0]

    coords1_rot = np.empty_like(coords1)
    for idx in range(natoms):
        coords1t = coords1[idx,:] + trans1
        coords1t = coords1t[:,np.newaxis]
        coords1_rot[idx,:] = np.dot(rotmat, coords1t).flatten() - trans2

    # load coordinates of second pose (non-hydrogen atoms)
    coords2 = mol2.get_coordinates(file2, keep_h=False)
    coords2 = np.array(coords2)

    rmsd = np.sqrt(np.sum((coords1_rot-coords2)**2)/natoms)
    return rmsd

def check_architecture(directory):
    """Check architecture %s*/%s*/%s* of specified directories"""%(ligdir_prefix,tardir_prefix,isodir_prefix)

    if os.path.isdir(directory):
        dir_split = directory.split('/')
        if dir_split[-1].startswith(isodir_prefix):
            isisomerID = True
            if len(dir_split) > 1 and dir_split[-2].startswith(tardir_prefix):
                istargetID = True
                if len(dir_split) > 2 and dir_split[-3].startswith(ligdir_prefix):
                    isligID = True
                else:
                    isligID = False
            elif len(dir_split) > 1 and dir_split[-2].startswith(ligdir_prefix):
                istargetID = False
                isligID = True
            else:
                istargetID = False
                isligID = False
        elif dir_split[-1].startswith(tardir_prefix):
            isisomerID = False
            istargetID = True
            if len(dir_split) > 1 and dir_split[-2].startswith(ligdir_prefix):
                isligID = True
            else:
                isligID = False
        elif dir_split[-1].startswith(ligdir_prefix):
            isisomerID = False
            istargetID = False
            isligID = True
        else:
            isisomerID = False
            istargetID = False
            isligID = False

    return isligID, istargetID, isisomerID

def get_IDs(directory, isligID, istargetID, isisomerID):
    """Get IDs of ligand target and isomer (if applicable) according to the current architecture."""

    if isisomerID:
        isomerID = directory.split('/')[-1]
        if istargetID:
            targetID = directory.split('/')[-2]
            if isligID:
                ligID = directory.split('/')[-3]
            else:
                ligID = None
        elif isligID:
            targetID = None
            ligID = directory.split('/')[-2]
        else:
            targetID = None
            ligID = None
    elif istargetID:
        isomerID = None
        targetID = directory.split('/')[-1]
        if isligID:
            ligID = directory.split('/')[-2]
        else:
            ligID = None
    elif isligID:
        isomerID = None
        targetID = None
        ligID = directory.split('/')[-1]
    else:
        isomerID = None
        targetID = None
        ligID = None

    return ligID, targetID, isomerID

def check_directories(dirs):
    if dirs != ['.']:
        iscwd = False
        for jdx, dir in enumerate(dirs):
            isligID, istargetID, isisomerID = check_architecture(dir)
            if jdx == 0:
                isligID_ref = isligID
                istargetID_ref = istargetID
                isisomerID_ref = isisomerID
            elif isligID != isligID_ref or istargetID != istargetID_ref or isisomerID != isisomerID_ref:
                raise ValueError("%s*/%s*/%s* architecture architecture inconsistent between folders!"%(ligdir_prefix,tardir_prefix,isodir_prefix))
    else:
        iscwd = True
        isligID = False
        istargetID = False
        isisomerID = False

    return iscwd, isligID, istargetID, isisomerID

def add_names(csvfile, df):

    df_ligands = pd.read_csv(csvfile)

    if 'isomer' in df_ligands:
        df_ligands = df_ligands[df_ligands['isomer']==1]

    df = df.merge(df_ligands[['ligID', 'name']], on='ligID')
    return df

def get_total_residue_number(filename):

    indices = []
    nresidues = 0

    with open(filename, 'r') as pdbf:
        for line in pdbf:

            if line.startswith('ATOM'):
                resnum = line[22:26].strip()

                if resnum not in indices:
                    indices.append(resnum)
                    nresidues += 1
    return nresidues

def get_sequence_from_PDB(filename):

    indices = []
    sequence = ''
    with open(filename, 'r') as pdbf:
        for line in pdbf:

            if line.startswith('ATOM'):
                resnum = line[22:26].strip()
                resname = line[17:20].strip()

                if resname in equivalent_residues:
                    resname = equivalent_residues[resname]

                if resnum not in indices and resname in residues_3_to_1:
                    sequence += residues_3_to_1[resname]
                    indices.append(resnum)

    return sequence, indices

def get_residues_coordinates(filename, indices):

    indices_new = []
    coords = []

    with open(filename, 'r') as pdbf:
        for line in pdbf:
            if line.startswith('ATOM'):

                resnum = line[22:26].strip()
                resname = line[17:20].strip()
                atomname = line[12:16].strip()

                if resnum not in indices_new and resnum in indices:
                    coords.append([])
                    indices_new.append(resnum)

                if resnum in indices and resname[0] != 'H':
                    x = float(line[30:38])
                    y = float(line[38:46])
                    z = float(line[46:54])
                    coords[-1].append([atomname, x, y, z])

    return coords, indices_new

def get_rmsd_rotation_and_translations(file1, file2):

    nres1 = get_total_residue_number(file1)
    nres2 = get_total_residue_number(file2)

    seq1, ind1 = get_sequence_from_PDB(file1)
    seq2, ind2 = get_sequence_from_PDB(file2)

    alignment = nw.global_align(seq1, seq2)

    nalign = len(alignment[0])
    nresidues_min = min(len(seq1), len(seq2))

    ind1new = []
    ind2new = []
    idx1, idx2 = 0, 0

    for idx in range(nalign):
        if (idx < nresidues_min) and seq1[idx] == seq2[idx] and seq1[idx] != '-':
            ind1new.append(ind1[idx1])
            ind2new.append(ind2[idx2])
        if (idx < len(seq1)) and seq1[idx] != '-':
            idx1 += 1
        if (idx < len(seq2)) and seq2[idx] != '-':
            idx2 += 1

    ind1 = ind1new
    ind2 = ind2new

    frac1 = len(ind1)*100.0/nres1
    frac2 = len(ind2)*100.0/nres2
    #print frac1, frac2
    #TODO: add a threshold for the number of residues considered

    # get coordinates of specific residues 
    coords1, ind1 = get_residues_coordinates(file1, ind1)
    coords2, ind2 = get_residues_coordinates(file2, ind2)

    new_coords1 = []
    new_coords2 = []

    # check if there is consistency in atom names
    nresidues1 = len(coords1)
    for idx in range(nresidues1):
        coords1_res = coords1[idx]
        coords2_res = coords2[idx]

        atomnames1 = [item[0] for item in coords1_res]
        atomnames2 = [item[0] for item in coords2_res]
        if set(atomnames1) != set(atomnames2):
            sys.exit("Inconsistency found in residue %s in file %s and residue %s in file %s! Missing atom suspected..."%(ind1[idx],file1,ind2[idx],file2))

        # create new coordinates
        for an1, x1, y1, z1 in coords1_res:
            for an2, x2, y2, z2 in coords2_res:
                if an1 == an2:
                    new_coords1.append([x1, y1, z1])
                    new_coords2.append([x2, y2, z2])
                    break

    new_coords1 = np.array(new_coords1).T
    new_coords2 = np.array(new_coords2).T

    rotation = np.zeros(9)
    trans1 = -new_coords1[:,0]
    trans2 = -new_coords2[:,0]

    rmsd = pyqcprot.CalcRMSDRotationalMatrix(new_coords1, new_coords2, rotation, None)

    rotation = rotation.reshape((3, 3))
    trans1 += new_coords1[:,0]
    trans2 += new_coords2[:,0]

    return rotation, trans1, trans2

def get_rmsd_rotation_and_translations_all_targets(files_r):
    
    rmsd_rot_trans = {}
    for key1 in files_r:
        rmsd_rot_trans[key1] = {}

        for key2 in files_r:
            if key1 == key2:
                rotation = np.eye(3)
                trans1 = np.zeros(3)
                trans2 = np.zeros(3)
            else:
                file1 = files_r[key1]
                file2 = files_r[key2]
                rotation, trans1, trans2 = get_rmsd_rotation_and_translations(file1, file2)
            rmsd_rot_trans[key1][key2] = [rotation, trans1, trans2]

    return rmsd_rot_trans

dirs = []
for dir in args.dirs:
    if os.path.isdir(dir+'/poses'):
        dirs.append(os.path.relpath(dir))
    else:
        raise ValueError('directory '+dir+'/poses does not exist!')
iscwd, isligID, istargetID, isisomerID = check_directories(dirs)

# check if info related to targets is there!
if not args.csvfile_r:
    for dir in args.dirs:
        # check if .pdb files are there
        if not os.path.isdir(dir+'/poses/rec.pdb'):
            sys.exit("PDB file rec.pdb for receptor not found in %s!"%dir)
elif os.path.isfile(args.csvfile_r):
    df_targets = pd.read_csv(args.csvfile_r)
    csvfile_r_dir = os.path.dirname(args.csvfile_r)
    # update relative paths
    for column in ['file_origin', 'pdbfile']:
        df_targets[column] =  df_targets[column].apply(lambda x: os.path.relpath(csvfile_r_dir+'/'+x))
else:
    sys.exit("File %s does not exist!"%args.csvfile_r)

# check options relative to best poses extraction
scoring_functions_all = []
if args.sbcd:
    scoring_functions = args.sbcd
    if len(args.sbcd) < 2:
        raise ValueError('Number of functions for score-based consensus docking should be at least 2!')
    resolve_with = args.sbcd[0] # used to decide which pose to extract when selecting over all targets and isomers
elif args.cd:
    scoring_functions = None
    if len(args.cd) < 2:
        raise ValueError('Number of programs for consensus docking should be at least 2!')
    resolve_with = 'score'
elif args.sf:
    scoring_functions = args.sf
    resolve_with = 'score_multi'

features = ['file_l', 'file_r', 'site', 'program', 'instance', 'index_pose']
if args.csvfile_l:
    if not os.path.isfile(args.csvfile_l):
        raise IOError("csvfile %s not found!"%args.csvfile_l)

features_ids = []
if isligID:
    features_ids += ['ligID']
if istargetID:
    features_ids += ['targetID']
if isisomerID:
    features_ids += ['isomerID']

files_r = {}
poses = []
for jdx, dir in enumerate(dirs):
    posedir = dir + '/poses'
    ligID, targetID, isomerID = get_IDs(dir, isligID, istargetID, isisomerID)

    info_dir = {}
    for ft in features_ids + features + ['score']:
        info_dir[ft] = []

    # get location of poses and receptor files
    with open(posedir+'/info.dat', 'r') as inff:
        # skip the first two lines
        inff.next()
        inff.next()

        for line in inff:
            program, nposes, firstidx, site = line.strip().split(',')
            firstidx = int(firstidx)
            nposes = int(nposes)
            instance = program
            if site:
                instance += '.' + site
            poses_idxs = range(firstidx, firstidx+nposes)

            nposes = len(poses_idxs)
            for index, idx in enumerate(poses_idxs):
                file_l = posedir + '/lig-%s.mol2'%idx
                if os.path.isfile(file_l):
                    info_dir['file_l'].append(os.path.relpath(file_l))
                else:
                    raise IOError("File %s does not exist!"%file_l)
                info_dir['site'].append(site)
                info_dir['program'].append(program)
                info_dir['instance'].append(instance)
                info_dir['index_pose'].append(index)
                if isligID:    
                    info_dir['ligID'].append(ligID)
                if istargetID:
                    info_dir['targetID'].append(targetID)
                if isisomerID:
                    info_dir['isomerID'].append(isomerID)
                
                # get the filename of the corresponding receptor file
                if not args.csvfile_r:
                    file_r = os.path.relpath(posedir+'/rec.pdb')
                else:
                    row = df_targets[df_targets['targetID']==targetID]
                    file_r = row['pdbfile'].values[0]
                info_dir['file_r'].append(file_r)

                # update the dictionnary of targets
                if targetID not in files_r:
                    files_r[targetID] = file_r

            nscores = 0
            # extract original scores
            with open(dir+'/'+instance+'/score.out', 'r') as sout:
                for line_s in sout:
                    nscores += 1
                    info_dir['score'].append(float(line_s.strip()))
                if nscores != nposes:
                    raise ValueError("Number of poses different from number of scores (%s/%s)"%(dir,instance))

    # extract all scores
    for score_file in sorted(glob(dir+'/rescoring/*.score')):
        sf = os.path.basename(score_file).split('.')[0]
        if jdx == 0:
            scoring_functions_all.append(sf)
        elif sf not in scoring_functions_all:
            raise ValueError("%s scores not computed in every directory!")
        info_dir[sf] = []
        with open(score_file, 'r') as sout:
            for line_s in sout:
                info_dir[sf].append(float(line_s))

    df_dir = pd.DataFrame(info_dir)
    if args.docking_programs: 
        df_dir = df_dir[df_dir['instance'].isin(args.docking_programs)]
    poses.append(df_dir)

if poses:
    poses = pd.concat(poses).reset_index()
    if args.csvfile_l and isligID:
        poses = add_names(args.csvfile_l, poses)
else:
    sys.exit("No poses to extract!")

if args.combine_targets and istargetID:
    groupby_columns = []
    if isligID:
        groupby_columns += ['ligID']
    if isisomerID:
        groupby_columns += ['isomerID']

    if args.sbcd or args.cd:
        rmsd_rot_trans = get_rmsd_rotation_and_translations_all_targets(files_r)
        best_poses = []
        if args.sbcd:
            poses_groupby = poses.groupby(groupby_columns)
            for sf in scoring_functions:
                best_poses_sf = poses.loc[poses_groupby[sf].idxmin]
                best_poses_sf = best_poses_sf.drop(['index', 'index_pose'], axis=1)

                new_columns_names = [] # renaming columns according to the scoring function
                for col in best_poses_sf.columns.values:
                    if col in ['ligID', 'isomerID']:
                        new_columns_names.append(col)
                    else:
                        new_columns_names.append(col + '_' + sf)
                best_poses_sf.columns = new_columns_names
                best_poses.append(best_poses_sf)
        else:
            for prgm in args.cd:
                poses_prgm = poses[poses['program']==prgm]
                poses_groupby = poses_prgm.groupby(groupby_columns)
        
                best_poses_prgm = poses_prgm.loc[poses_groupby['score'].idxmin]
                best_poses_sf = best_poses_prgm.drop(['index', 'index_pose'], axis=1)
 
                new_columns_names = [] # renaming columns according to the scoring function
                for col in best_poses_sf.columns.values:
                    if col in ['ligID', 'isomerID']:
                        new_columns_names.append(col)
                    else:
                        new_columns_names.append(col + '_' + sf)
                best_poses_sf.columns = new_columns_names
                best_poses.append(best_poses_sf)

        # merge best poses into single dataframe
        best_poses_merged = best_poses[0]
        for best_pose_sf in best_poses[1:]:
            best_poses_merged = best_poses_merged.merge(best_poses_sf, on=groupby_columns)
        print best_poses_merged
        sys.exit()

        if args.sbcd:
            programs = scoring_functions
        else:
            programs = args.cd

        sf_first = programs[0]
        # try to find if there is a consensus
        for sf in programs[1:]:
            best_poses_merged['rmsd_'+sf_first+'_'+sf] = best_poses_merged.apply(lambda row: compute_rmsd(row['file_l_'+sf_first], row['file_l_'+sf],
            rotmat=rmsd_rot_trans[row['targetID_'+sf_first]][row['targetID_'+sf]][0], \
            trans1=rmsd_rot_trans[row['targetID_'+sf_first]][row['targetID_'+sf]][1], \
            trans2=rmsd_rot_trans[row['targetID_'+sf_first]][row['targetID_'+sf]][2]), axis=1)
            #best_poses_merged['rmsd_'+sf_first+'_'+sf] = best_poses_merged.apply(lambda row: compute_rmsd(row['file_l_'+sf_first], row['file_l_'+sf]), axis=1)
        rmsd_columns = [col for col in best_poses_merged.columns.values if col.startswith('rmsd')]
        best_poses_merged = best_poses_merged.assign(consensus=(best_poses_merged[rmsd_columns]<=args.cutoff).all(axis=1))
        print best_poses_merged
        sys.exit()        

#    else: 
#        groupby_columns = []
#        if isligID:
#            groupby_columns += ['ligID']
#        if isisomerID:
#            groupby_columns += ['isomerID']
#        if groupby_columns:
#            poses_groupby = poses.groupby(groupby_columns)
#            poses = poses.loc[poses_groupby[resolve_with].idxmin]
#        else:
#            poses = poses.loc[poses[resolve_with].idxmin].T
#        print poses
#        sys.exit()
#
# determine best poses according to strategy provided
if args.combine_isomers:
    if isisomerID:
        groupby_columns = []
        if isligID:
            groupby_columns += ['ligID']
        if istargetID:
            groupby_columns += ['targetID']
        if groupby_columns:
            poses_groupby = poses.groupby(groupby_columns)
            poses = poses.loc[poses_groupby[resolve_with].idxmin]
        else:
            poses = best_poses.loc[poses[resolve_with].idxmin].T


shutil.rmtree(args.resultsdir, ignore_errors=True)
os.mkdir(args.resultsdir)

features_csv = list(features_ids)
if args.csvfile_l:
    features_csv.append('name')
features_csv += features + scoring_functions_all + ['score']

if args.sf:
    features_csv.append('score_multi')

features_csv.remove('instance')
features_csv.remove('index_pose')

# save poses to .csv file
poses[features_csv].to_csv(args.resultsdir+'/poses.csv', index=False, float_format='%.3f')

if args.combine_isomers and isisomerID:
    features_ids.remove('isomerID')
if args.combine_targets and istargetID:
    features_ids.remove('targetID')

if best_poses is not None:
    best_poses[features_csv].to_csv(args.resultsdir+'/best_poses.csv', index=False, float_format='%.3f')
    for idx, row in best_poses.iterrows():
        newdir = args.resultsdir + '/' + '/'.join(row[features_ids])
        if not os.path.isdir(newdir):
            os.makedirs(newdir)
        file_l = row['file_l']
        file_r = row['file_r']
        instance = row['instance']
        index = row['index_pose']
    
        shutil.copyfile(file_l, newdir+'/ligand.mol2')
        origindir = '/'.join(file_l.split('/')[:-2])
    
        poses_idxs = []
        for filename in glob(origindir+'/'+instance+'/lig-*.mol2'):
            poses_idxs.append(int((filename.split('.')[-2]).split('-')[-1]))
        poses_idxs = sorted(poses_idxs)
        pose_idx = poses_idxs[int(index)]
    
        if os.path.isdir(origindir+'/'+instance+'/origin'):
            shutil.copyfile(origindir+'/'+instance+'/origin/lig-%i.mol2'%pose_idx, newdir+'/ligand_orig.mol2')
        shutil.copyfile(file_r, newdir+'/protein.pdb')
else:
    sys.exit("No poses found for the selected method of extraction!")
